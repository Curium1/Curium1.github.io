---
layout: post
title:  "robots.txt"
date:   2017-11-04 21:16:00 -0500
categories: instructions
---
The file robots.txt is a file that robots such as crawlers can use in order to index a site the way it is intended by the author. The file (also called The Robots Exclusion Protocol) specifies what folders and files that the robot should ignore. The reason i write *should* ignore is that the file can be ignored if instructed to.

The protocol is considered a standard but it is not governd by any institute neither is it actively developed.

In my project i have chosen to omit all folders except the site folder since that is where the published site will be. All other folders contains workfiles.

I've put the original file in the folder src. I wans't sure that it was the right place in order for Jekyll to compile it the right way but as the site compiled it seemed to work fine. and now it can be found at {{site.url}}/robots.txt,